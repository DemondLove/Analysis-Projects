---
title: "Assignment 5.2 - Housing Data"
author: "Demond Love"
date: "7/6/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Data for this assignment is focused on real estate transactions recorded from 1964 to 2016 and can be found in Week 5 Housing.xlsx. Using your skills in statistical correlation, regression and R programming, you are interested in the following variables: Sale Price and Square Footage of Lot.**
```{r, results='hide', warning = FALSE, message = FALSE}
library(readxl)
library(ggplot2)
library(pastecs)
library(ggm)
file = read_excel("/Users/Love/Documents/DSC 520 Statistics for Data Science/Week 5 DSC 520/week-5-housing.xlsx")
data = data.frame(file$`Sale Price`, file$sq_ft_lot)
names(data) = c("sale_price", "sq_footage")
```

**Examine the data set visually and numerically. Are there missing data? Does that data contain outliers? Explain how you will handle missing data and outliers so you have a clean data set going forward.**

Checking the structure of the dataset; its class, variable classes, column names, number of rows, and number of columns.
```{r}
str(data)
```
Checking basic descriptive statistics about the dataset.
```{r}
summary(data)
```
Check how many NAs are in each variable.
```{r}
sapply(data, function(x) {sum(is.na(x))})
```

```{r}
ggplot(data, aes(data$sale_price, data$sq_footage)) + geom_point() + scale_x_continuous(name="Square Footage", labels = scales::comma)
```
```{r}
dataoutlier1 = subset(data, data$sale_price <= 14000 & data$sq_footage > 50000)
dataoutlier1
```
These are all of the outliers in which the price of the home was less than $14,001, but the home had more than 50,000 sqare feet. These cases can be removed from the dataset, since there must be a data entry error (+50,000 square foot properties will almost never sell for this small amount), there are a few of them so they drastically impact the underlying integrity of the sample, and I beleive these not to be from the population that we intended for this sample.
```{r}
dataoutlier2 = subset(data, data$sale_price > 3000000 & data$sq_footage < 5000)
# dataoutlier2
```
These outliers seem extremely high at a price per square foot level, but a quick google search can validate these prices. The below article notes multiple properties with this price per square footage, including a 12,500-square-foot mansion in Atherton Calif. for $22.8 million. Seeing that none of our 3 or 4 million dollar properies are sub-2000-square-feet, then these are all typically in the range of this mansion.

Therefore, there are no NAs in this dataset, and the only outliers that need to be excluded are the homes with astronomical square-footage, but extremely low prices.

```{r}
cleaneddata = data[!(data$sale_price <= 14000 & data$sq_footage > 50000),]
nrow(cleaneddata)
```

```{r}
summary(cleaneddata)
```

**Construct scatterplots for the variables in R studio and place the best-fit linear regression line on each scatterplot. Describe the relationship between the variables in each plot.**
```{r, warning = FALSE, message = FALSE}
ggplot(cleaneddata, aes(cleaneddata$sale_price, cleaneddata$sq_footage)) + 
    geom_point() + 
    scale_x_continuous(name="Sales Price", labels = scales::comma) + 
    scale_y_continuous(name="Square Footage", labels = scales::comma) + 
    geom_smooth(methode = lm)
```

This scatterplot presents a strong, neutral, non-linear relationship. Although the data points are clustered together, there doesn't seem to be any relationship between the number of square feet and the price of the homes. This is probably due to the fact that we aren't taking the location of the property into account. After all, real estate is all about "Location, Location, Location!"

**Use R to calculate the covariance of the two variables and provide an explanation of why you would use this calculation and what the results indicate.**
```{r}
round(cov(cleaneddata), digits = 2)
```
The covariance between these variables is 3,054,347,576. This figure is a measure of how these two variables covary, which is measure of how their variances align. Essentially, when one variable deviates from its mean, then if these varaiables were related, then we would expect the other variable to deviate from its mean in a similar way.

**Choose the type of correlation test to perform, explain why you chose this test, and make a prediction if the test yields a positive or negative correlation?**

I am unable to use the Pearson correlation, since one of its basic assumptions of the underlying data is that it is normally distributed (tests & results shown later). Therefore, Spearman’s correlation coefficient can be used when the data has violated parametric assumptions such as non-normally distributed data.

I predict that these variables will have a very weak, negative correlation.

**Perform a correlation analysis of the variables and describe what the calculations in the correlation matrix suggest about the relationship between the variables. Be specific with your explanation. Calculate the correlation coefficient and the coefficient of determination, describe what you conclude about the results.**
```{r}
cor(cleaneddata$sale_price, cleaneddata$sq_footage, method = "spearman")
```
The correlation coefficient here is 0.16, which indicates a nearly non-existently weak, positive correlation. With 0 meaning that there is no relationship and 1 meaning that there is a perfect, positive relationship, this is a very weak value.
```{r}
cor(cleaneddata$sale_price, cleaneddata$sq_footage, method = "spearman")^2*100
```
As opposed to the correlation coefficient, described earlier, the coefficient of determination is a measure of the amount of variablility in one variable that is shared by others.

From this, you can see that only 2.7% of the variance in sale price is accounted for by square footage.

**Based on your analysis what can you say about the relationship between the variables?**

Based on this analysis, there does appear to be little or no relationship between these variables, which is supported by the graphs above.

**Produce an appropriate graph for the variables. Use R Markdown to report, critique and discuss the skewness and any significant scores found.**

Running Histogram and checking for outliers and normality.
```{r, warning = FALSE, message = FALSE}
ggplot(cleaneddata, aes(cleaneddata$sale_price)) + geom_histogram(bins = 14) + scale_x_continuous(name="Sale Price", labels = scales::comma)
```
Presenting normality numerically. Taking a 5,000 sample to use the stat.desc function.
```{r}
sale_pricesample = sample(cleaneddata$sale_price, size = 5000)
round(stat.desc(sale_pricesample, basic = FALSE, norm = TRUE), digits = 0)
```
Running Histogram and checking for outliers and normality.
```{r, warning = FALSE, message = FALSE}
ggplot(cleaneddata, aes(cleaneddata$sq_footage)) + geom_histogram(bins = 14) + scale_x_continuous(name="Square Footage", labels = scales::comma)
```
Presenting normality numerically. Taking a 5,000 sample to use the stat.desc function.
```{r}
sq_footagesample = sample(cleaneddata$sq_footage, size = 5000)
round(stat.desc(sq_footagesample, basic = FALSE, norm = TRUE), digits = 0)
```
**Perform a partial correlation, “controlling” for at least two variables. Explain how this changes your interpretation and explanation of the results.**
```{r}
names(file)
```
```{r}
partialcordata = data.frame(file$`Sale Price`, file$sq_ft_lot, file$bedrooms, file$year_built)
names(partialcordata) =c("sale_price", "sq_footage", "bedrooms", "year_built")
cleanedpartialcordata = partialcordata[!(partialcordata$sale_price<=14000&partialcordata$sq_footage>50000),]
nrow(cleanedpartialcordata)
```

```{r}
pc = pcor(c("sale_price", "sq_footage", "bedrooms", "year_built"), var(partialcordata))
pc
```
```{r}
pcor.test(pc, 2, 12850)
```
Surprisingly, controlling for the number of bedrooms and year the home was built didn't have much of an impact of the correlation analysis. The correlation coefficient went from 0.16 to 0.15.

**Choose Square Footage of Lot as the Predictor and Sale Price as the Outcome and perform a regression analysis.**
```{r}
modeldata = lm(cleaneddata$sale_price ~ cleaneddata$sq_footage)
summary(modeldata)
```


**What are the intercept and the slope? What are the coefficient of determination and the correlation coefficient?**

The intercept is 637,872, the slope is 1.08. coefficient of determination is 0.02, and the correlation coefficient is 0.16.

**For this model, what variation exists. Be specific in your response.**

There is a lot of variation in this model. In fact, only 2% of variation in sales prices can be explained by square footage alone. Therefore, there must be other variables that have an influence also. This is representative by the R-squared value in the regression analysis.

**Based on the calculated F-Ratio does this regression model result in a better prediction of the sale price than if you had chosen to use the mean value of square footage of lot?**

For this dataset, the F-ratio is 266.3, which is significan’t at p < .001ˆ4. Therefore, we conclude that our regression model results in significantly better predictions than the mean.

**Use the model to make a prediction of your choice. Explain the values you use in the model and the resulting prediction as well as how someone might benefit from using this model.**

I am going to choose to predict the sales price of a home with 75,000 square feet. However, based on the above analysis, I do not think that this model or prediction will benefit anyone. There relationship between these two variables is simply too weak for regression analysis to make an appropriate predictive model tool.

```{r}
coeffs = coefficients(modeldata)
m = coeffs[2]
b = coeffs[1]
prediction = m*75000 + b
prediction
```
The sales price that was projected for a 75,000 square foot home would be $719,241.90.
